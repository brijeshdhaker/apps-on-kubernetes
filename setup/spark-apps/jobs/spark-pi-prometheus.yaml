#
# kubectl -n spark-apps apply -f setup/spark-apps/jobs/spark-pi-prometheus.yaml
# kubectl -n spark-apps delete -f setup/spark-apps/jobs/spark-pi-prometheus.yaml
#
# kubectl -n spark-apps describe sparkapplication spark-pi-prometheus
# kubectl -n spark-apps get sparkapplication spark-pi-prometheus
# kubectl -n spark-apps delete sparkapplications spark-pi-prometheus
#
# kubectl -n spark-apps delete pods -l kubernetes_executor=True -l spark-role=driver
#
# kubectl -n spark-apps port-forward svc/spark-apps-prometheus-service 4040:4040
#

apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-pi-prometheus
  namespace: spark-apps
spec:
  type: Scala
  mode: cluster
  image: "docker.io/brijeshdhaker/spark:3.1.2"
  imagePullPolicy: Always
  mainClass: org.apache.spark.examples.SparkPi
  mainApplicationFile: "local:///opt/spark/examples/jars/spark-examples_2.12-3.1.2.jar"
  sparkConf:
    spark.eventLog.enabled: 'true'
    spark.eventLog.dir: 'file:///mnt/nfs_share/spark-logs/'
    spark.ui.prometheus.enabled: "true"
    spark.metrics.conf: "/opt/spark/metrics/metrics.properties"
    spark.metrics.staticSources.enabled: "true"
    spark.metrics.appStatusSource.enabled: "true"
    spark.executor.processTreeMetrics.enabled: "true"
  arguments:
    - "100000"
  sparkVersion: "3.1.2"
  restartPolicy:
    type: Never
#  sparkUIOptions:
#    servicePortName: "spark-ui"
#    servicePort: 4040
#    serviceAnnotations:
#      prometheus.io/scrape: "true"
#      prometheus.io/port: "4040"
#      prometheus.io/path: "/metrics/executors/prometheus/"
  volumes:
    - name: "nfs-volume"
      nfs:
        path: "/mnt/nfs_share"
        server: "192.168.122.1"
    - name: "host-volume"
      hostPath:
        path: "/mnt/local-share"
        type: Directory
    - name: "spark-volume"
      persistentVolumeClaim:
        claimName: "spark-volume"
    - name: "configmap-volume"
      configMap:
        name: "spark-apps-configmap"
        items:
          - key: "prometheus.metrics.properties"
            path: "metrics.properties"
  driver:
    cores: 1
    coreLimit: "1200m"
    memory: "640m"
    labels:
      app.kubernetes.io/version: 3.1.2
      app.kubernetes.io/component: spark-driver
      app.kubernetes.io/part-of: spark
      app.kubernetes.io/managed-by: self
      app.kubernetes.io/metrics-by: prometheus
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "4040"
      prometheus.io/path: "/metrics/prometheus/"
    serviceAnnotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "4040"
      prometheus.io/path: "/metrics/executors/prometheus/"
    serviceAccount: spark
    volumeMounts:
      - name: "nfs-volume"
        mountPath: "/mnt/nfs_share"
      - name: "configmap-volume"
        mountPath: "/opt/spark/metrics"
      - name: "spark-volume"
        mountPath: "/mnt/spark-apps"
    javaOptions: "-Divy.cache.dir=/tmp -Divy.home=/tmp"
  executor:
    cores: 1
    instances: 1
    memory: "640m"
    labels:
      app.kubernetes.io/version: 3.1.2
      app.kubernetes.io/component: spark-executor
      app.kubernetes.io/part-of: spark
      app.kubernetes.io/managed-by: self
      app.kubernetes.io/metrics-by: prometheus
    volumeMounts:
      - name: "nfs-volume"
        mountPath: "/mnt/nfs_share"
      - name: "configmap-volume"
        mountPath: "/opt/spark/metrics"
      - name: "spark-volume"
        mountPath: "/mnt/spark-apps"
    javaOptions: "-Divy.cache.dir=/tmp -Divy.home=/tmp"